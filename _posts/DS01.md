최근에 학교 공부에 집중을 하느라, 많은 것에 투자하기 힘든 것 같습니다.

1전공인 물리학을 5과목, 2전공인 컴퓨터 과학을 2과목 수강하면서 다양한 스터디와 단체의 대표를 맡아서 이끌어 가는게 확실히 쉬운일은 아니라고 느낍니다.

그래서 근래에 깃헙이 됐든, 블로그가 됐든 아주 뜸한 활동을 이어가고 있습니다. 특히 블로그 같은 경우에는 전반적으로 이전의 글들을 수정할 계획을 갖고 있는데,,, (계획만) ㅋㅋㅋㅋㅋ
아직 더 갈 길이 먼 것 같습니다..

시작을 조금이라도 단축 하면서 나의 블로그에 글을 영차 영차 남기기 위해 학교에서 배우는 것을 바탕으로 정리하며 글을 작성해 나가려 합니다.

자료구조! 시작!

## 프로그램의 효율성은 어떻게 측정하는가?
어떻게 프로그램의 효율성을 측정하는 가는 프로그래머들이라면 당연하게도 관심을 가질 주제입니다. 그렇기에 대부분의 컴퓨터 관련학과에서 가르치는 과목이 자료구조이지요.

그렇다면 그 방법은 어떻게 될까요? 잘 감이 오지 않으시다면, 우리가 최소값을 찾는 경우를 가정하고, 어떻게 하면 효율적일 수 있는가에 대해서 얘기해보도록 합시다.

#### 예제 코드
다음의 최소값 탐색 코드를 한 번 봅시다.

~~~
for(int i = 0; i < n; i++){
    isMin = true;
    for(j = 0; j < n; j++){
        if(a[j] < a[i]) isMin = false;
    }
    if (isMin) min = a[i];
}
~~~

이 코드를 해석하면 다음과 같습니다.

a의 j번째 값이 I번째 값 보다 크면 isMin을 true로 변경 후 최소를 a의 i번째 값으로 지정. -> 이것을 n x n 번 반복

그렇다면 다음의 코드는 어떤가요?

~~~
min = a[0];
for(i = 1; i < n; i++){
    if(a[i] < min) min = a[i];
}
~~~

위 코드를 해석하면, min에 a의 첫번째 요소를 저장하고 min과 a의 i 번째 요소를 비교해가며 a[i]가 클 경우 min을 a[i]로 교체. -> 이것을 n번 반복

우리는 두 코드를 보고 직관적으로 두번째의 코드가 좋다는 것을 알 수 있습니다. 그런데 이를 논리적으로 그리고 프로그래밍적 관점에서 어떻게 명확히 무엇이 더 낫다라고 말할 수 있을까요?

#### 두 가지 방식의 효율성 지표
여기에는 다음의 두 가지의 답이 존재합니다.
1. Empirically(경험적): 실질적인 데이터로 실행 시간을 측정하자!
2. Analytically(해석적): input size에 대한 수식으로 시간을 “표현”하자

결론부터 말하자면, 2번이 주로 쓰이게 됩니다. 그 이유는 1번이 실행 시간을 어느 정도다! 하고 보장해주지 못하기 때문이지요.

#### Analytically한 방법의 3가지 가정
그렇다면 어떻게 2번을 이용하여 해석적으로 판단하게 될까요? 다음의 세 가정은 해석적 방법의 목표를 달성하기위해 정한 것입니다.
1. 더하기는 1 nano second가 소요된다.
2. 두 값의 비교는 1 nano second가 소요된다.
3. assignment는 0 nano second가 소요된다.

그러나 3번째 가정의 경우, 실질적으로는 잘못된 가정에 해당합니다. 그럼에도 이것이 유용한 가정으로 사용되는 이유는 추후 배울 asymptotic notation 때문이라 할 수 있습니다. 추후에 다시 언급하겠습니다.

#### Analytically 표현 방식 예제
다시 위에서 제시한 2개의 코드로 돌아가 실행 시간 정도를 Analytically하게 표현해봅시다!

첫번째의 경우 맨 처음 for문에서 n번, 2번째 for문에서 n + 1번 실행하므로 $n(n + 1) = n^2 + n$으로 표현이 가능합니다.

한편, 두번째의 경우에는 for문에서 n-1번 반복하고, if문을 매 for문마다 1번씩 실행하므로 $n - 1$으로 표현이 가능합니다.

따라서 두번째의 경우가 첫번째의 경우보다 더 효율적이라고 할 수 있겠습니다.

## Asynmptotic Notation
위에서 살펴보았듯이, 우리는 Analytically한 방법을 사용하여 프로그래밍의 효율성을 input size에 대해 표현할 수 있었습니다.
그런데 이 방법의 단점은 너무 많은 코드에 대해 처리할 수 없을 때가 많다는 것입니다. 

따라서, 수많은 양의 코드를 어림잡아 취하는 방식을 사용하기로 하였습니다. 점근 표기법(asymptotic notation)은 그것을 대표하는 효과적인 방식이고, 이것을 이용하여 프로그램의 효율성을 근사적으로 표현할 수 있습니다.

이러한 asymptotic notation은 $O, \Omega, \Theta$의 3 종류가 존재합니다.

각각의 정의는 조금 복잡하기에 이를 간단히 다음과 같이 표기하였습니다.
* $f(n) \le Cg(n)$일 때, $f(n) = O(g(n))$
* $f(n) \ge Cg(n)$일 때, $f(n) = \Omega(g(n))$  
* $f(n) = O(g(n)) = \Omega(g(n))$일 때, $\Theta(g(n))$

즉, 간단하게 외우면 최대 길이를 보장하는 것은 $O$, 최소 길이를 보장하는 것은 $\Omega$ 둘이 같을 땐, $Theta$입니다.

#### 주의사항
* 실행 시간은 input size 뿐만 아니라, input contents에 따라서도 달라질 수 있습니다.
* 최악의 상황(worst case)를 고려하여 수행시간을 보장하는 big-O 표기법을 주로 사용합니다.

## Space Complexity
우리는 이제까지 사실 수행 시간만을 집중하여 프로그램의 효율성을 판단하였습니다. 그러나, "효율적인 프로그래밍이 무엇인가" 하고 물었을 때, 그것을 작동 시키기에 충분하지 않은 메모리를 지녀 작동 자체가 불가능할 경우도 있습니다.

즉, 우리는 수행시간 이외에도 얼마나 많은 메모리를 차지하는가를 고려해야 합니다. 그리고 이러한 메모리(에 저장하는 것)는 시간 복잡도를 줄여주는 하나의 수단이 될 수 있습니다.

가령, 점화식의 경우에는 이전의 값을 메모리에 저장한다면, 이것을 효율적으로 활용하여 시간복잡도를 줄일 수 있을 것입니다.

이를 두고 time-space trade off라고 부르며, 컴퓨터과학에서 중요한 요소로 사용되기도 합니다.

#### Example
질문에 답을 해보는 문제를 만들어 봅시다. q(x, y) = sum a[x] to a[y]와 같은 문제가 있다고 가정하고, 다음의 세가지 버전의 코드를 봅시다.

~~~
# ver.1
answer = 0;
for(i = x; i <= y; i++){
  answer += a[i];
}

# ver.2 - preprocessing1
for(i = 0; i < n; i++){
  sum[i] = sum[i - 1] + a[i];
  for(j = i + 1; j < n; j++){
    sum[i][j] = sum[i][j - 1] + a[j];
  }
}
answer = sum[x][y];


# ver.3 - preprocessing2
sum[0] = a[0];
for(i = 1; i<=n; i++){
  sum[i] = sum[i - 1] + a[i];
}
if (x == 0){
  answer = sum[y];
}else{
  answer = sum[y] - sum[x - 1];
}
~~~

위 세 가지 코드를 분석해봅시다!

우선 첫 번째 버전같은 경우, 공간 복잡도는 $O(1)$이라고 할 수 있습니다. 하나의 변수에 값을 계속 추가하는 방식이기 때문이죠.

두 번째 버전의 경우, 공간복잡도는 $O(n^2)$일 것입니다. 이것은 2차원의 배열을 사용하여 저장하기 때문입니다.

마지막 버전같은 경우에는 $O(n)$이 됩니다. 1차원의 배열을 사용하기 때문이죠.

따라서, 공간복잡도만 고려한다면 첫 번째, 세 번째, 두 번째 순으로 그 효율성이 결정될 것입니다.

#### 시간복잡도 관점에서의 해석
그러나, 우리는 앞에서 배운 시간 복잡도까지 함께 고려해야 합니다.

시간복잡도는 각각 $O(nq), O(n^2 + q), O(n + q)$가 되고 이는 q의 크기에 따라 그 복잡도 역시 영향을 받는다는 것을 의미합니다. 그리고 그 유불리 역시 나뉠 것입니다.

종합적으로 고려했을 때, 마지막의 것이 가장 효율적이라고 할 수는 있겠으나, 역시 단점이 존재합니다. n이 너무 클 경우 overflow가 발생할 수 있다는 것입니다.

가령, q(999, 1000)일때, 세 번째 방법에 따르면 1000까지의 합 - 999까지의 합을 해야합니다. 답은 1000번째 수이니 그리 크지 않을 수 있으나, 1000까지의 합을 저장하는 것에서 overflow의 위험이 존재합니다.
